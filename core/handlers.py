import tempfile

from aiogram import Router, types, F
from aiogram.filters import CommandStart, Command

from core.app import bot
from core.config import BOT_USERNAME
from core.constants import LLM_MODELS, SUPPORTED_MSG_TYPES
from utils import llm_utils, stt_utils
from utils.db_utils import get_chat_llm, set_chat_llm
from utils.logging_utils import log_message, logger

start_router = Router()


@start_router.message(CommandStart())
async def cmd_start(message: types.Message):
    user = message.from_user
    username = f"@{user.username}" if user.username else f"{user.first_name or user.id}"
    uid = message.from_user.id

    welcome_text = (
        f"ü§ì *Nerdinzzz* ‚Äì –≤–∞—à —É–º–Ω—ã–π —á–∞—Ç-–±–æ—Ç –Ω–∞ –±–∞–∑–µ LLM (OpenAI, Qwen, Llama –∏ –¥—Ä—É–≥–∏–µ)!\n\n"
        "–û–Ω –º–≥–Ω–æ–≤–µ–Ω–Ω–æ –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ —É–º–µ–µ—Ç –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å –≥–æ–ª–æ—Å–æ–≤—ã–µ –≤ —Ç–µ–∫—Å—Ç.\n\n"
        "–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ, –∏ –±–æ—Ç —Å—Ä–∞–∑—É –¥–∞—Å—Ç –æ—Ç–≤–µ—Ç!\n\n"
        "üîó –î–æ–±–∞–≤—å—Ç–µ –±–æ—Ç–∞, —Ä–∞–∑—Ä–µ—à–∏—Ç–µ –¥–æ—Å—Ç—É–ø –∫ —Å–æ–æ–±—â–µ–Ω–∏—è–º, –∏ –æ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:\n"
        "   ‚Ä¢ –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Ç–µ–∫—Å—Ç\n"
        f"   ‚Ä¢ –û—Ç–≤–µ—Ç–∏—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã, –µ—Å–ª–∏ —É–ø–æ–º—è–Ω—É—Ç—å `@{BOT_USERNAME}`"
    )

    await message.answer(welcome_text, parse_mode="Markdown")
    logger.info(f"User {username} ({uid}) started the bot")


@start_router.message(F.content_type == "voice")
async def voice_handler(message: types.Message):
    voice = message.voice
    file = await bot.get_file(voice.file_id)

    with tempfile.NamedTemporaryFile(suffix=".ogg") as tmp:
        await bot.download_file(
            file.file_path,
            destination=tmp.name
        )
        stt_response = await stt_utils.stt(tmp.name)

        log_message(message=message, stt_response=stt_response)
        await message.reply(stt_response)


@start_router.message(F.content_type == "video_note")
async def video_note_handler(message: types.Message):
    video_note = message.video_note
    file = await bot.get_file(video_note.file_id)

    with tempfile.NamedTemporaryFile(suffix=".mp4") as tmp:
        await bot.download_file(
            file.file_path,
            destination=tmp.name)
        stt_response = await stt_utils.stt_from_video(tmp.name)

        log_message(message=message, stt_response=stt_response)
        await message.reply(stt_response)


@start_router.message(Command("set_llm"))
async def set_llm_handler(message: types.Message):
    chat_id = message.chat.id
    text = message.text.replace("/set_llm ", "").strip()
    if not text:
        await message.answer("‚ùå –£–∫–∞–∂–∏—Ç–µ –∫–æ–¥ –º–æ–¥–µ–ª–∏ –ø–æ—Å–ª–µ /set_llm")
        return

    model_code = text
    if model_code not in LLM_MODELS:
        await message.answer("‚ùå –¢–∞–∫–æ–π –º–æ–¥–µ–ª–∏ –Ω–µ—Ç")
        return

    if message.chat.type in ("group", "supergroup"):
        member = await bot.get_chat_member(chat_id=chat_id, user_id=message.from_user.id)
        if member.status not in ("administrator", "creator"):
            await message.answer("‚ùå –¢–æ–ª—å–∫–æ –∞–¥–º–∏–Ω –º–æ–∂–µ—Ç –º–µ–Ω—è—Ç—å –º–æ–¥–µ–ª—å –≤ –≥—Ä—É–ø–ø–µ")
            return

    await set_chat_llm(chat_id, model_code)
    await message.answer(
        f"–ú–æ–¥–µ–ª—å `{LLM_MODELS[model_code]['name']}` —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ ‚úÖ",
        parse_mode="Markdown"
    )
    logger.warning(f"Chat {chat_id}: LLM changed to {model_code} by {message.from_user.id}")


# text + group + mention
@start_router.message(F.content_type == "text",
                      lambda m: m.chat.type in ("group", "supergroup"),
                      lambda m: m.text and m.text.startswith(f"@{BOT_USERNAME} "))
async def text_group_handler(message: types.Message):
    chat_id = message.chat.id
    text = message.text.replace(f'@{BOT_USERNAME} ', '').strip()
    if not text: return

    llm_code = await get_chat_llm(chat_id)
    llm_response = await llm_utils.get_llm_response(text, llm_code)

    log_message(message=message, llm_response=llm_response, llm_code=llm_code)
    await message.reply(llm_response)


@start_router.message(F.content_type == "text", F.chat.type == "private")
async def text_private_handler(message: types.Message):
    text = message.text
    chat_id = message.chat.id

    llm_code = await get_chat_llm(chat_id)
    llm_response = await llm_utils.get_llm_response(text, llm_code)

    log_message(message=message, llm_response=llm_response, llm_code=llm_code)
    await message.answer(llm_response)


@start_router.message(~F.content_type.in_(SUPPORTED_MSG_TYPES), F.chat.type == "private")
async def unsupported_handler(message: types.Message):
    log_message(message=message)
    await message.answer("‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Å–æ–æ–±—â–µ–Ω–∏—è")
