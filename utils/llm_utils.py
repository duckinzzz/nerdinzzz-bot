from groq import AsyncGroq

from core.bot_core import LLM_TOKEN, dp

client = AsyncGroq(api_key=LLM_TOKEN)


async def get_llm_response(user_prompt: str) -> str:
    system_prompt = (
        f"–¢—ã ‚Äî Nerdinzzz ü§ì, LLM —á–∞—Ç-–±–æ—Ç –Ω–∞ –±–∞–∑–µ {dp['llm']}. "
        "–¢–≤–æ–π —Å–æ–∑–¥–∞—Ç–µ–ª—å - @duckinzzz. "
        "–¢—ã —É–º–µ–µ—à—å –±—ã—Å—Ç—Ä–æ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤—ã–≤–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤—ã–µ –≤ —Ç–µ–∫—Å—Ç. "
        "–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, —è—Å–Ω–æ –∏ –ø–æ –¥–µ–ª—É, –º–∞–∫—Å–∏–º—É–º 3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. "
        "–ï—Å–ª–∏ –Ω—É–∂–µ–Ω —Å–ø–∏—Å–æ–∫ - —Ç–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã–µ –ø—É–Ω–∫—Ç—ã. "
        "–ù–µ –∑–∞–¥–∞–≤–∞–π –≤—Å—Ç—Ä–µ—á–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤, –Ω–µ –æ–±—ä—è—Å–Ω—è–π —Å–≤–æ–∏ –¥–µ–π—Å—Ç–≤–∏—è. "
    )
    messages = [
        {
            "role": "system",
            "content": system_prompt.lower()
        },
        {"role": "user", "content": user_prompt}
    ]

    completion = await client.chat.completions.create(model=dp['llm'], messages=messages, temperature=1,
                                                      max_completion_tokens=1024, top_p=1,
                                                      stream=False, stop=None)

    return completion.choices[0].message.content
