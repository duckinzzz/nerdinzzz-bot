import base64
import re
import tempfile

from aiogram import types
from groq import AsyncGroq

from core.app import bot
from core.config import LLM_TOKEN
from core.constants import LLM_MODELS
from utils.logging_utils import logger

client = AsyncGroq(api_key=LLM_TOKEN)


def remove_reasoning_tags(text: str) -> str:
    """
    –£–¥–∞–ª—è–µ—Ç reasoning —Ç–µ–≥–∏ –∏–∑ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏.
    Reasoning –æ–±—ã—á–Ω–æ –æ–±–µ—Ä–Ω—É—Ç –≤ <think>...</think> –∏–ª–∏ <reasoning>...</reasoning>
    """
    # –£–¥–∞–ª—è–µ–º <think>...</think>
    text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)
    # –£–¥–∞–ª—è–µ–º <reasoning>...</reasoning>
    text = re.sub(r'<reasoning>.*?</reasoning>', '', text, flags=re.DOTALL)
    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
    text = re.sub(r'\n\n+', '\n\n', text)
    return text.strip()


def encode_image(image_path: str) -> str:
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")


async def download_photo_to_base64(bot, photo: types.PhotoSize) -> str:
    """
    –°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–æ—Ç–æ –∏–∑ Telegram –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç base64 —Å—Ç—Ä–æ–∫—É
    """
    with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as tmp:
        file = await bot.get_file(photo.file_id)
        await bot.download_file(file.file_path, tmp.name)
        tmp.flush()
        return encode_image(tmp.name)


async def get_ocr_response(caption: str, photos: list[types.PhotoSize], llm_code: str) -> str:
    """
    caption: —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ / –ø–æ–¥–ø–∏—Å—å
    photos: —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ types.PhotoSize –∏–∑ Telegram
    llm_code: –∫–ª—é—á –∏–∑ LLM_MODELS
    """
    llm = LLM_MODELS[llm_code]

    system_prompt = f"""
    –¢—ã ‚Äî Nerdinzzz ü§ì, LLM —á–∞—Ç-–±–æ—Ç –Ω–∞ –±–∞–∑–µ {llm['name']}.
    –¢–≤–æ–π —Å–æ–∑–¥–∞—Ç–µ–ª—å ‚Äî @duckinzzz.
    –¢–≤–æ—è –∑–∞–¥–∞—á–∞:
    - –ë—ã—Å—Ç—Ä–æ –∏ —Ç–æ—á–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.
    - –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤—ã–≤–∞—Ç—å —Ç–µ–∫—Å—Ç —Å —Ñ–æ—Ç–æ –≤ —Ç–µ–∫—Å—Ç (OCR) –∏–ª–∏ –¥–∞–≤–∞—Ç—å –∫—Ä–∞—Ç–∫–∏–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é.
    - –û—Ç–≤–µ—á–∞—Ç—å –∫—Ä–∞—Ç–∫–æ, —è—Å–Ω–æ –∏ –ø–æ –¥–µ–ª—É, –º–∞–∫—Å–∏–º—É–º 3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.
    - –ï—Å–ª–∏ –Ω—É–∂–µ–Ω —Å–ø–∏—Å–æ–∫ ‚Äî —Ç–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã–µ –ø—É–Ω–∫—Ç—ã.
    - –ò—Å–ø–æ–ª—å–∑—É–π –Ω—É–º–µ—Ä–∞—Ü–∏—é –∏–ª–∏ –º–∞—Ä–∫–µ—Ä—ã –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤, –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ.
    - –ù–µ –∑–∞–¥–∞–≤–∞–π –≤—Å—Ç—Ä–µ—á–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤.
    - –ù–µ –æ–±—ä—è—Å–Ω—è–π —Å–≤–æ–∏ –¥–µ–π—Å—Ç–≤–∏—è –∏ –Ω–µ –¥–æ–±–∞–≤–ª—è–π –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è –∏–ª–∏ –ø—Ä–æ—â–∞–Ω–∏—è.
    - –í—Å–µ–≥–¥–∞ –ø—Ä–∏–¥–µ—Ä–∂–∏–≤–∞–π—Å—è –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –∏ –¥—Ä—É–∂–µ–ª—é–±–Ω–æ–≥–æ —Ç–æ–Ω–∞.
    - –ù–µ —ç–∫—Ä–∞–Ω–∏—Ä—É–π —Å–∏–º–≤–æ–ª—ã, –∫–∞–≤—ã—á–∫–∏ –∏–ª–∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –∑–Ω–∞–∫–∏ ‚Äî –≤—ã–≤–æ–¥–∏ —Ç–µ–∫—Å—Ç ¬´–∫–∞–∫ –µ—Å—Ç—å¬ª.
    """

    # –ö–æ–¥–∏—Ä—É–µ–º –≤—Å–µ —Ñ–æ—Ç–æ –≤ base64
    encoded_photos = []
    for photo in photos:
        b64 = await download_photo_to_base64(bot, photo)
        encoded_photos.append({
            "type": "image_url",
            "image_url": {"url": f"data:image/jpeg;base64,{b64}"}
        })

    user_content = [{"type": "text", "text": caption}] + encoded_photos

    messages = [
        {"role": "system", "content": system_prompt.lower()},
        {"role": "user", "content": user_content}
    ]

    kwargs = {
        "model": llm_code,
        "messages": messages,
        "temperature": 1,
        "max_completion_tokens": 4096,  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è reasoning –º–æ–¥–µ–ª–µ–π
        "top_p": 1,
        "stream": False,
        "stop": None,
    }

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ reasoning –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
    if llm.get('reasoning'):
        # –î–ª—è GPT-OSS –º–æ–¥–µ–ª–µ–π: –∏—Å–ø–æ–ª—å–∑—É–µ–º low effort + –ø–æ–∫–∞–∑—ã–≤–∞–µ–º reasoning
        if llm_code.startswith('openai/gpt-oss'):
            kwargs["reasoning_effort"] = "low"  # –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ
            # –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º include_reasoning=False, —Ç.–∫. —ç—Ç–æ –≤—Å—ë —Ä–∞–≤–Ω–æ –Ω–µ –æ—Ç–∫–ª—é—á–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
            # –í–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º reasoning –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        # –î–ª—è Qwen –º–æ–¥–µ–ª–µ–π: –º–æ–∂–Ω–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Ç–∫–ª—é—á–∏—Ç—å
        elif llm_code.startswith('qwen/'):
            kwargs["reasoning_effort"] = "none"

    try:
        completion = await client.chat.completions.create(**kwargs)
        content = completion.choices[0].message.content

        if not content or not content.strip():
            logger.error(
                f"LLM {llm_code} returned empty content. "
                f"Caption: {caption[:100]}"
            )
            return "‚ùå –ú–æ–¥–µ–ª—å –Ω–µ —Å–º–æ–≥–ª–∞ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–ª–∏ –º–æ–¥–µ–ª—å."

        return content.strip()

    except Exception as e:
        logger.error(f"Error in get_ocr_response: {e}")
        return f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}"


async def get_llm_response(user_prompt: str, llm_code: str) -> str:
    llm = LLM_MODELS[llm_code]

    system_prompt = f"""
    –¢—ã ‚Äî Nerdinzzz ü§ì, LLM —á–∞—Ç-–±–æ—Ç –Ω–∞ –±–∞–∑–µ {llm['name']}.
    –¢–≤–æ–π —Å–æ–∑–¥–∞—Ç–µ–ª—å ‚Äî @duckinzzz.
    –¢–≤–æ—è –∑–∞–¥–∞—á–∞:
    - –ë—ã—Å—Ç—Ä–æ –∏ —Ç–æ—á–Ω–æ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è.
    - –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤—ã–≤–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Ç–µ–∫—Å—Ç (–µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è).
    - –û—Ç–≤–µ—á–∞—Ç—å –∫—Ä–∞—Ç–∫–æ, —è—Å–Ω–æ –∏ –ø–æ –¥–µ–ª—É, –º–∞–∫—Å–∏–º—É–º 3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.
    - –ï—Å–ª–∏ –Ω—É–∂–µ–Ω —Å–ø–∏—Å–æ–∫ ‚Äî —Ç–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã–µ –ø—É–Ω–∫—Ç—ã.
    - –ò—Å–ø–æ–ª—å–∑—É–π –Ω—É–º–µ—Ä–∞—Ü–∏—é –∏–ª–∏ –º–∞—Ä–∫–µ—Ä—ã –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤, –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ.
    - –ù–µ –∑–∞–¥–∞–≤–∞–π –≤—Å—Ç—Ä–µ—á–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤.
    - –ù–µ –æ–±—ä—è—Å–Ω—è–π —Å–≤–æ–∏ –¥–µ–π—Å—Ç–≤–∏—è –∏ –Ω–µ –¥–æ–±–∞–≤–ª—è–π –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è –∏–ª–∏ –ø—Ä–æ—â–∞–Ω–∏—è.
    - –í—Å–µ–≥–¥–∞ –ø—Ä–∏–¥–µ—Ä–∂–∏–≤–∞–π—Å—è –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –∏ –¥—Ä—É–∂–µ–ª—é–±–Ω–æ–≥–æ —Ç–æ–Ω–∞.
    - –ù–µ —ç–∫—Ä–∞–Ω–∏—Ä—É–π —Å–∏–º–≤–æ–ª—ã, –∫–∞–≤—ã—á–∫–∏ –∏–ª–∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –∑–Ω–∞–∫–∏ ‚Äî –≤—ã–≤–æ–¥–∏ —Ç–µ–∫—Å—Ç ¬´–∫–∞–∫ –µ—Å—Ç—å¬ª.
    """

    messages = [
        {
            "role": "system",
            "content": system_prompt.lower()
        },
        {"role": "user", "content": user_prompt}
    ]

    kwargs = {
        "model": llm_code,
        "messages": messages,
        "temperature": 1,
        "max_completion_tokens": 4096,  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è reasoning –º–æ–¥–µ–ª–µ–π
        "top_p": 1,
        "stream": False,
        "stop": None,
    }

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ reasoning –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
    if llm.get('reasoning'):
        # –î–ª—è GPT-OSS –º–æ–¥–µ–ª–µ–π: –∏—Å–ø–æ–ª—å–∑—É–µ–º low effort + –ø–æ–∫–∞–∑—ã–≤–∞–µ–º reasoning
        if llm_code.startswith('openai/gpt-oss'):
            kwargs["reasoning_effort"] = "low"  # –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ
            # –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º include_reasoning=False, —Ç.–∫. —ç—Ç–æ –≤—Å—ë —Ä–∞–≤–Ω–æ –Ω–µ –æ—Ç–∫–ª—é—á–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
            # –í–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º reasoning –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        # –î–ª—è Qwen –º–æ–¥–µ–ª–µ–π: –º–æ–∂–Ω–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Ç–∫–ª—é—á–∏—Ç—å
        elif llm_code.startswith('qwen/'):
            kwargs["reasoning_effort"] = "none"

    try:
        completion = await client.chat.completions.create(**kwargs)
        content = completion.choices[0].message.content

        if not content or not content.strip():
            logger.error(
                f"LLM {llm_code} returned empty content. "
                f"Prompt: {user_prompt[:100]}"
            )
            return "‚ùå –ú–æ–¥–µ–ª—å –Ω–µ —Å–º–æ–≥–ª–∞ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å –∏–ª–∏ —Å–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å."

        return content.strip()

    except Exception as e:
        logger.error(f"Error in get_llm_response: {e}")
        return f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}"
